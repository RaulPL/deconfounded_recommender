{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import arviz as az\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import random\n",
    "from jax.scipy.special import expit\n",
    "\n",
    "import numpyro\n",
    "import numpyro.distributions as dist\n",
    "from numpyro.distributions import constraints\n",
    "from numpyro.infer import SVI, Trace_ELBO, Predictive, NUTS, MCMC\n",
    "\n",
    "rng_np = np.random.default_rng(101)\n",
    "n_factors_pmf = 10\n",
    "n_factors_exposure = 20\n",
    "K = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MovieLens data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "names = ['userId', 'movieId', 'rating', 'timestamp']\n",
    "df_ratings = pd.read_csv('./ml-100k/u.data', sep='\\t', names=names)\n",
    "df_ratings = df_ratings.drop('timestamp', axis=1)\n",
    "print(df_ratings.shape)\n",
    "df_ratings.head(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Taken from https://docs.pymc.io/notebooks/probabilistic_matrix_factorization.html\n",
    "\n",
    "# Define a function for splitting train/test data.\n",
    "def split_train_test(data, percent_test, rng):\n",
    "    \"\"\"Split the data into train/test sets.\"\"\"\n",
    "    n, m = data.shape             # # users, # movies\n",
    "    N = n * m                     # # cells in matrix\n",
    "    # Prepare train/test ndarrays.\n",
    "    train = data.copy()\n",
    "    test = np.ones(data.shape) * np.nan\n",
    "    # Draw random sample of training data to use for testing.\n",
    "    tosample = np.where(~np.isnan(train))       # ignore nan values in data\n",
    "    idx_pairs = list(zip(tosample[0], tosample[1]))   # tuples of row/col index pairs\n",
    "    test_size = int(len(idx_pairs) * percent_test)  # use a % of data as test set\n",
    "    train_size = len(idx_pairs) - test_size   # and remainder for training\n",
    "    indices = np.arange(len(idx_pairs))         # indices of index pairs\n",
    "    sample = rng.choice(indices, replace=False, size=test_size)\n",
    "    # Transfer random sample from train set to test set.\n",
    "    for idx in sample:\n",
    "        idx_pair = idx_pairs[idx]\n",
    "        test[idx_pair] = train[idx_pair]  # transfer to test set\n",
    "        train[idx_pair] = np.nan          # remove from train set\n",
    "    # Verify everything worked properly\n",
    "    assert(train_size == N-np.isnan(train).sum())\n",
    "    assert(test_size == N-np.isnan(test).sum())\n",
    "    # Return train set and test set\n",
    "    return train, test\n",
    "\n",
    "\n",
    "all_users = np.sort(df_ratings.userId.unique())\n",
    "all_movies = np.sort(df_ratings.movieId.unique())\n",
    "df_dense_data = df_ratings.pivot_table(index='userId', columns='movieId', values='rating')\n",
    "assert all(df_dense_data.columns == all_movies)\n",
    "assert all(df_dense_data.index == all_users)\n",
    "\n",
    "train, test = split_train_test(df_dense_data.values, 0.2, rng=rng_np)\n",
    "del df_dense_data\n",
    "print(train.shape, test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "n_users, n_items = train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exposure model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "exposure_train = jnp.nan_to_num(train, nan=0)\n",
    "exposure_train = jnp.where(exposure_train > 0, 1, 0)\n",
    "print(exposure_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(exposure_train.mean(), exposure_train.sum(), jnp.count_nonzero(exposure_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pf_model(\n",
    "    n_users: int, \n",
    "    n_items: int, \n",
    "    n_factors: int, \n",
    "    exposure=None, \n",
    "    # **kwargs\n",
    "):\n",
    "    \"\"\"Generative program of the Poisson factorization model\"\"\"\n",
    "    a = 0.23\n",
    "    b = 1 / a\n",
    "    prefs = numpyro.sample('prefs', dist.Gamma(a, b), sample_shape=(n_users, n_factors))\n",
    "    atts = numpyro.sample('atts', dist.Gamma(a, b), sample_shape=(n_items, n_factors))\n",
    "    rates = numpyro.deterministic('rates', prefs @ atts.T)\n",
    "    obs = numpyro.sample('obs', dist.Poisson(rates), obs=exposure)\n",
    "    return obs\n",
    "\n",
    "\n",
    "def pf_guide(\n",
    "    n_users: int, \n",
    "    n_items: int, \n",
    "    n_factors: int, \n",
    "    exposure=None, \n",
    "):\n",
    "    \"\"\"Poisson factorization guide.\"\"\"\n",
    "    a_prefs = numpyro.param(\n",
    "        'a_prefs', \n",
    "        jnp.ones((n_users, n_factors)) * 0.23, \n",
    "        constraint=constraints.positive\n",
    "    )\n",
    "    a_atts = numpyro.param(\n",
    "        'a_atts', \n",
    "        jnp.ones((n_items, n_factors)) * 0.23, \n",
    "        constraint=constraints.positive\n",
    "    )\n",
    "    b_prefs = 1 / a_prefs\n",
    "    b_atts = 1 / a_atts\n",
    "    prefs = numpyro.sample('prefs', dist.Gamma(a_prefs, b_prefs))\n",
    "    atts = numpyro.sample('atts', dist.Gamma(a_atts, b_atts))\n",
    "    rates = numpyro.deterministic('rates', prefs @ atts.T)\n",
    "    return rates\n",
    "\n",
    "\n",
    "with numpyro.handlers.seed(rng_seed=10134):\n",
    "    prior_sample = pf_model(n_users, n_items, n_factors_exposure)\n",
    "    print(prior_sample.shape)\n",
    "    print(prior_sample.mean(), prior_sample.sum(), jnp.count_nonzero(prior_sample))\n",
    "    guide_vals = pf_guide(n_users, n_items, n_factors_exposure)\n",
    "    print(guide_vals.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVI\n",
    "n_iters = 15\n",
    "step_size = 0.01\n",
    "optimizer = numpyro.optim.Adam(step_size=step_size)\n",
    "svi = SVI(pf_model, pf_guide, optimizer, loss=Trace_ELBO())\n",
    "\n",
    "init_state = svi.init(\n",
    "    random.PRNGKey(202), \n",
    "    n_users, n_items, n_factors_exposure, exposure_train\n",
    ")\n",
    "state, losses = jax.lax.scan(\n",
    "    lambda state, i: svi.update(state, n_users, n_items, n_factors_exposure, exposure_train), \n",
    "    init_state, jnp.arange(n_iters)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(losses);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(n_iters):\n",
    "    svi_state, loss = svi.update(\n",
    "        svi_state, \n",
    "        n_users, n_items, n_factors_exposure, exposure_train\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: initialize model with result of SVI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "nuts_kernel = NUTS(poisson_factorization_model)\n",
    "mcmc = MCMC(nuts_kernel, num_samples=500, num_warmup=1000, num_chains=1)\n",
    "rng_key = random.PRNGKey(1234)\n",
    "# mcmc.warmup()\n",
    "mcmc.run(rng_key, exposure_train, n_factors_exposure)\n",
    "posterior_samples = mcmc.get_samples()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outcome model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "confounders = jnp.load('./substitute_confounders.npy')\n",
    "print(confounders.shape)\n",
    "train_no_nan = jnp.nan_to_num(train, nan=0)\n",
    "print(train_no_nan.shape)\n",
    "\n",
    "scaled_ratings = (train - 1) / (K - 1)\n",
    "# pd.Series(scaled_ratings.flatten()).plot.hist()\n",
    "scaled_ratings = jnp.nan_to_num(scaled_ratings, nan=0)\n",
    "print(scaled_ratings.shape)\n",
    "# scaled_ratings\n",
    "exposure_train = jnp.nan_to_num(train, nan=0)\n",
    "exposure_train = jnp.where(exposure_train > 0, 1, 0)\n",
    "print(exposure_train.shape)\n",
    "exposure_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def pmf_model(exposure, confounders, ratings, n_factors: int, **kwargs):\n",
    "    n_users, n_items = exposure.shape\n",
    "    s = 0.1\n",
    "    U = numpyro.sample('U', dist.Normal(0., s), sample_shape=(n_users, n_factors))\n",
    "    V = numpyro.sample('V', dist.Normal(0., s), sample_shape=(n_items, n_factors))\n",
    "    gammas = numpyro.sample('gammas', dist.Normal(0., 1), sample_shape=(n_users, 1))\n",
    "    mean = (U @ V.T) * exposure + (gammas * confounders)\n",
    "    mean = expit(mean)\n",
    "    scale = jnp.ones_like(mean) * 0.001\n",
    "    r = numpyro.sample('R', dist.Normal(mean, scale), obs=ratings)\n",
    "    return mean\n",
    "\n",
    "\n",
    "with numpyro.handlers.seed(rng_seed=101):\n",
    "    res_model = pmf_model(exposure_train, confounders, scaled_ratings, n_factors_pmf)\n",
    "    print(res_model.shape)\n",
    "    print(res_model.min(), res_model.mean(), res_model.max())\n",
    "res_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "nuts_kernel = NUTS(pmf_model)\n",
    "mcmc = MCMC(nuts_kernel, num_samples=500, num_warmup=1000, num_chains=1)\n",
    "rng_key = random.PRNGKey(15)\n",
    "mcmc.run(rng_key, exposure_train, confounders, scaled_ratings, n_factors_pmf)\n",
    "posterior_samples = mcmc.get_samples()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Functions taken from https://docs.pymc.io/notebooks/probabilistic_matrix_factorization.html\n",
    "\n",
    "def rmse(test_data, predicted):\n",
    "    \"\"\"Calculate root mean squared error.\n",
    "    Ignoring missing values in the test data.\n",
    "    \"\"\"\n",
    "    I = ~jnp.isnan(test_data)   # indicator for missing values\n",
    "    N = I.sum()                # number of non-missing values\n",
    "    sqerror = jnp.power(test_data - predicted, 2)\n",
    "    mse = sqerror[I].sum() / N                 # mean squared error\n",
    "    return jnp.sqrt(mse)\n",
    "\n",
    "\n",
    "def mae(test_data, predicted):\n",
    "    \"\"\"Calculate Mean Absolute Error Ignoring missing values\"\"\"\n",
    "    I = ~jnp.isnan(test_data)   # indicator for missing values\n",
    "    N = I.sum()                # number of non-missing values\n",
    "    abserror = jnp.abs(test_data - predicted)\n",
    "    mae = abserror[I].sum() / N   # mean squared error\n",
    "    return mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def pmf_predict(U, V, gammas, confounders, k):\n",
    "    mean = (U @ V.T) * 1. + (gammas * confounders)\n",
    "    scaled_mean = expit(mean)\n",
    "    preds = scaled_mean * (k - 1) + 1\n",
    "    return preds\n",
    "\n",
    "# samples\n",
    "U_samples = jnp.load('./samples/U.npy')\n",
    "V_samples = jnp.load('./samples/V.npy')\n",
    "gammas_samples = jnp.load('./samples/gammas.npy')\n",
    "beta_0_samples = jnp.load('./samples/beta_0.npy')\n",
    "\n",
    "# params\n",
    "U = np.median(U_samples, axis=0)\n",
    "V = np.median(V_samples, axis=0)\n",
    "gammas = np.median(gammas_samples, axis=0)\n",
    "beta_0 = np.median(beta_0_samples, axis=0)\n",
    "\n",
    "assert n_factors_pmf == U.shape[1]\n",
    "assert n_factors_pmf == V.shape[1]\n",
    "\n",
    "preds_pmf = pmf_predict(U, V, gammas, confounders, K)\n",
    "print(preds_pmf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print('RMSE:', rmse(test, preds_pmf))\n",
    "print('MAE:', mae(test, preds_pmf))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
